---
title: "Optimizing Grasping in Legged Robots: A Deep Learning Approach to Loco-Manipulation"
collection: publications
category: conferences
permalink: /publication/2025_lars-4
excerpt: 'This paper introduces a deep learning framework designed to enhance the grasping capabilities of quadrupeds equipped with arms, focusing on improved precision and adaptability.'
date: 2025-10-03
venue: '2025 IEEE Latin American Robotics Symposium (LARS)'
paperurl: 'https://arxiv.org/abs/2508.17466'
citation: 'Almeida, Dilermando, Guilherme Lazzarini, Juliano Negri, Thiago H. Segreto, Ricardo V. Godoy, and Marcelo Becker. "Optimizing Grasping in Legged Robots: A Deep Learning Approach to Loco-Manipulation." arXiv preprint arXiv:2508.17466 (2025).'
---

Quadruped robots have emerged as highly efficient and versatile platforms, excelling in navigating complex and unstructured terrains where traditional wheeled robots might fail. Equipping these robots with manipulator arms unlocks the advanced capability of loco-manipulation to perform complex physical interaction tasks in areas ranging from industrial automation to search-and-rescue missions. However, achieving precise and adaptable grasping in such dynamic scenarios remains a significant challenge, often hindered by the need for extensive real-world calibration and pre-programmed grasp configurations. This paper introduces a deep learning framework designed to enhance the grasping capabilities of quadrupeds equipped with arms, focusing on improved precision and adaptability. Our approach centers on a sim-to-real methodology that minimizes reliance on physical data collection. We developed a pipeline within the Genesis simulation environment to generate a synthetic dataset of grasp attempts on common objects. By simulating thousands of interactions from various perspectives, we created pixel-wise annotated grasp-quality maps to serve as the ground truth for our model. This dataset was used to train a custom CNN with a U-Net-like architecture that processes multi-modal input from an onboard RGB and depth cameras, including RGB images, depth maps, segmentation masks, and surface normal maps. The trained model outputs a grasp-quality heatmap to identify the optimal grasp point. We validated the complete framework on a four-legged robot. The system successfully executed a full loco-manipulation task: autonomously navigating to a target object, perceiving it with its sensors, predicting the optimal grasp pose using our model, and performing a precise grasp. This work proves that leveraging simulated training with advanced sensing offers a scalable and effective solution for object handling.
