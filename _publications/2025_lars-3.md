---
title: "A Synthetic Dataset for Manometry Recognition in Robotic Applications"
collection: publications
category: conferences
pubtype: conference
tags: [sim2real, perception, vision]
doi: 10.1109/LARS69345.2025.11272958        # optional
code: https://figshare.com/articles/figure/SynthetcData_ManometryInterpretation/29936768/1
permalink: /publication/2025_lars-3
excerpt: 'This paper addresses the challenges of data scarcity and high acquisition costs for training robust object detection models in complex industrial environments, such as offshore oil platforms'
date: 2025-10-03
venue: '2025 IEEE Latin American Robotics Symposium (LARS)'
paperurl: 'https://arxiv.org/abs/2508.17468'
citation: 'P. A. R. Saraiva, E. F. d. Souza, J. M. H. Pinheiro, T. H. Segreto, R. V. Godoy and M. Becker, "A Synthetic Dataset for Manometry Recognition in Robotic Applications," 2025 Latin American Robotics Symposium (LARS), Monterrey, Mexico, 2025, pp. 1-6, doi: 10.1109/LARS69345.2025.11272958. keywords: {Training;Accuracy;Service robots;Video sequences;Robot sensing systems;Data models;Stability analysis;Thermal stability;Synthetic data;Videos}'
---

This work addresses the challenges of data scarcity and high acquisition costs for training robust object detection models in complex industrial environments, such as offshore oil platforms. The practical and economic barriers to collecting real-world data in these hazardous settings often hamper the development of autonomous inspection systems. To overcome this, in this work we propose and validate a hybrid data synthesis pipeline that combines procedural rendering with AI-driven video generation. Our methodology leverages BlenderProc to create photorealistic images with precise annotations and controlled domain randomization, and integrates NVIDIA's Cosmos-Predict2 world-foundation model to synthesize physically plausible video sequences with temporal diversity, capturing rare viewpoints and adverse conditions. We demonstrate that a YOLO-based detection network trained on a composite dataset, blending real images with our synthetic data, achieves superior performance compared to models trained exclusively on real-world data. Notably, a 1:1 mixture of real and synthetic data yielded the highest accuracy, surpassing the real-only baseline. These findings highlight the viability of a synthetic-first approach as an efficient, cost-effective, and safe alternative for developing reliable perception systems in safety-critical and resource-constrained industrial applications
