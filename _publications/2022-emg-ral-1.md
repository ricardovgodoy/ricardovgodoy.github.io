---
title: "Electromyography-Based, Robust Hand Motion Classification Employing Temporal Multi-Channel Vision Transformers"
collection: publications
category: manuscripts
pubtype: journal
tags: [biosignal, grasping, manipulation, control, wearable-sensing]
doi: 10.1109/LRA.2022.319262
permalink: /publication/2022-emg-ral-1
excerpt: 'In this work, we propose Temporal Multi-Channel Vision Transformers as a deep learning technique that has the potential to achieve dexterous control of robots and bionic hands. The performance of this method is evaluated and compared with other well-known methods, employing the open-access Ninapro dataset.'
date: 2022-07-20
venue: 'IEEE RA-L'
paperurl: 'https://ieeexplore.ieee.org/document/9834070'
bibtexurl: 'http://ricardovgodoy.github.io/files/2022-emg-ral-1.bib'
citation: 'R. V. Godoy et al., "Electromyography-Based, Robust Hand Motion Classification Employing Temporal Multi-Channel Vision Transformers," in IEEE Robotics and Automation Letters, vol. 7, no. 4, pp. 10200-10207, Oct. 2022, doi: 10.1109/LRA.2022.3192623.'
---
With an increasing use of robotic and bionic devices for the execution of everyday life, complex tasks, Electromyography (EMG) based interfaces are being explored as candidate technologies for facilitating an intuitive interaction with such devices. However, EMG-based interfaces typically require appropriate features to be extracted from the raw EMG signals using a plethora of feature extraction methods to achieve excellent performance in practical applications. To select an appropriate feature set that will lead to significant EMG-based decoding performance, a deep understanding of available methods and the human musculoskeletal system is needed. To overcome this issue, researchers have proposed the use of deep learning methods for automatically extracting complex features directly from the raw EMG data. In this work, we propose Temporal Multi-Channel Vision Transformers as a deep learning technique that has the potential to achieve dexterous control of robots and bionic hands. The performance of this method is evaluated and compared with other well-known methods, employing the open-access Ninapro dataset.
