---
title: "MIHRaGe: A Mixed-Reality Interface for Human-Robot Interaction via Gaze-Oriented Control"
collection: publications
category: preprints
permalink: /publication/2025-arxiv-3
excerpt: 'This paper presents the MIHRAGe interface, an integrated system that combines gaze-tracking, robotic assistance, and a mixed-reality to create an immersive environment for controlling the robot using only eye movements.'
date: 2025-05-06
venue: 'arXiv'
paperurl: 'https://arxiv.org/abs/2505.03929'
bibtexurl: 'http://ricardovgodoy.github.io/files/2025-arxiv-3.bib'
citation: 'Baptista, Rafael R., Nina R. Gerszberg, Ricardo V. Godoy, and Gustavo JG Lahr. "MIHRaGe: A Mixed-Reality Interface for Human-Robot Interaction via Gaze-Oriented Control." arXiv preprint arXiv:2505.03929 (2025).'
---

Individuals with upper limb mobility impairments often require assistive technologies to perform activities of daily living. While gaze-tracking has emerged as a promising method for robotic assistance, existing solutions lack sufficient feedback mechanisms, leading to uncertainty in user intent recognition and reduced adaptability. This paper presents the MIHRAGe interface, an integrated system that combines gaze-tracking, robotic assistance, and a mixed-reality to create an immersive environment for controlling the robot using only eye movements. The system was evaluated through an experimental protocol involving four participants, assessing gaze accuracy, robotic positioning precision, and the overall success of a pick and place task. Results showed an average gaze fixation error of 1.46 cm, with individual variations ranging from 1.28 cm to 2.14 cm. The robotic arm demonstrated an average positioning error of +-1.53 cm, with discrepancies attributed to interface resolution and calibration constraints. In a pick and place task, the system achieved a success rate of 80%, highlighting its potential for improving accessibility in human-robot interaction with visual feedback to the user.
