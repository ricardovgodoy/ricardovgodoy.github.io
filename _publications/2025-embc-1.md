---
title: "On the Impact of Different Light Wavelengths in Decoding Human Intention in Lightmyography Controlled Prosthetic Hands"
collection: publications
category: conferences
pubtype: conference
tags: [biosignal, manipulation, grasping, wearable-sensing, control]
doi: 10.1109/EMBC58623.2025.11252975
permalink: /publication/2025-embc-1
excerpt: 'This study seeks to examine the impact of using different wavelengths of light in the decoding of hand postures using different machine learning methods.'
date: 2025-08-01
venue: '2025 47th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)'
paperurl: 'https://ieeexplore.ieee.org/document/11252975'
citation: 'B. Guan, R. V. Godoy, A. Dwivedi and M. Liarokapis, "On the Impact of Different Light Wavelengths in Decoding Human Intention in Lightmyography Controlled Prosthetic Hands," 2025 47th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Copenhagen, Denmark, 2025, pp. 1-7, doi: 10.1109/EMBC58623.2025.11252975. keywords: {Hands;Computer vision;Machine learning algorithms;Light emitting diodes;Transformers;Skin;Decoding;Linear discriminant analysis;Convolutional neural networks;Random forests}'
---

Lightmyography is a method of human interfacing proposed for the control of prosthetic systems in which light is reflected on the skin and captured using photosensors. While sharing conceptual similarities with forcemyography, lightmyo-graphy differentiates itself in the way it interacts with the skin due to skin optics. Different wavelengths of light interact with the skin in different depths and degrees, a principle utilized in photoplethysmography to estimate heart rate and blood oxygen levels. Therefore, lightmyography was previously designed with two wavelengths of light, green and near-infrared. This study seeks to examine the impact of using different wavelengths of light in the decoding of hand postures using different machine learning methods. Four light configurations were tested: using only green light, using only infrared light, using both green and infrared light blinking alternately each 250 ms, and finally using both lights blinking at 125 ms. Data was decoded using four machine learning algorithms, namely linear discriminant analysis, random forest, convolutional neural networks, and a transformer-based model. Statistical testing showed no significant effect from light configuration in the machine learning decoding of hand posture performance. The dataset collected in this study has been made available for further investigation.
