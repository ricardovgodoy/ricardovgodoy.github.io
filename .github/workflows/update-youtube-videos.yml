name: Update YouTube videos list

on:
  workflow_dispatch:
  schedule:
    - cron: "0 9 * * *" # daily at 09:00 UTC (06:00 Sao Paulo)

concurrency:
  group: yt-videos-${{ github.ref_name }}
  cancel-in-progress: true

permissions:
  contents: write

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Generate _data/videos.yml from YouTube
        env:
          CHANNEL_URL: "https://www.youtube.com/@RicardoVGodoy"
        run: |
          python - << 'PY'
          import os, re, urllib.request, xml.etree.ElementTree as ET

          channel_url = os.environ["CHANNEL_URL"].strip()

          # 1) Fetch channel page HTML (to extract channel id)
          req = urllib.request.Request(
              channel_url,
              headers={
                  "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36",
                  "Accept-Language": "en-US,en;q=0.9",
              },
          )
          html = urllib.request.urlopen(req, timeout=30).read().decode("utf-8", errors="ignore")

          # Common patterns:
          # - <meta itemprop="channelId" content="UC....">
          # - <link rel="canonical" href="https://www.youtube.com/channel/UC....">
          m = re.search(r'<meta[^>]+itemprop="channelId"[^>]+content="(UC[^"]+)"', html)
          if not m:
              m = re.search(r'rel="canonical"\s+href="https://www\.youtube\.com/channel/(UC[^"?/]+)"', html)

          if not m:
              raise SystemExit(
                  "Could not extract channel ID from channel HTML. "
                  "Open the channel page source and search for 'channelId' or 'canonical'."
              )

          channel_id = m.group(1)
          print("Channel ID:", channel_id)

          # 2) Fetch YouTube Atom feed
          feed_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
          xml = urllib.request.urlopen(feed_url, timeout=30).read()

          root = ET.fromstring(xml)
          ns = {
              "atom": "http://www.w3.org/2005/Atom",
              "yt": "http://www.youtube.com/xml/schemas/2015",
          }

          entries = []
          for e in root.findall("atom:entry", ns):
              vid = e.findtext("yt:videoId", default="", namespaces=ns)
              title = e.findtext("atom:title", default="", namespaces=ns)
              published = e.findtext("atom:published", default="", namespaces=ns)  # ISO datetime
              if not vid or not title or not published:
                  continue
              # Use stable thumbnail host
              thumb = f"https://i.ytimg.com/vi/{vid}/hqdefault.jpg"
              entries.append((published, title, vid, thumb))

          entries.sort(reverse=True)  # newest first

          os.makedirs("_data", exist_ok=True)
          out_path = "_data/videos.yml"
          with open(out_path, "w", encoding="utf-8") as f:
              for published, title, vid, thumb in entries:
                  safe_title = title.replace("\\", "\\\\").replace('"', '\\"')
                  f.write(f'- title: "{safe_title}"\n')
                  f.write(f'  youtube_id: "{vid}"\n')
                  f.write(f'  date: "{published[:10]}"\n')
                  f.write(f'  thumbnail: "{thumb}"\n')

          print(f"Wrote {len(entries)} videos to {out_path}")
          PY

      - name: Commit updates
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          branch: ${{ github.ref_name }}
          commit_message: "Update videos list [skip ci]"
          file_pattern: "_data/videos.yml"
